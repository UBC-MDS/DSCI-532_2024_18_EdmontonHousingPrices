{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "003409c7-cd7c-4121-ae67-55eb2bcb2942",
   "metadata": {},
   "outputs": [],
   "source": [
    "### This script is to record the model development for the illustration of the prediction page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2776391-bdc0-4707-8edd-68cf04559c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f8fbe6c-2af9-4471-91ec-8e60e534c30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/raw/listings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "efa5eebc-92ee-47c8-9703-899af302cf34",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"bathroom_adjusted\"] = data[\"bathrooms_text\"].str.extract(r'([0-9.]+)', expand = False).astype(float)\n",
    "data[\"price_adjusted\"] = data[\"price\"].str.extract(r'([0-9.]+)', expand = False).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "669f6516-ffdd-4fcd-9a94-5b42ad0adc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['longitude','latitude','accommodates','room_type','beds','bathroom_adjusted','price_adjusted']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "989dc6e2-0f3b-4281-a335-ecc480c42b6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression:\n",
      "Mean Squared Error: 12414.222560145628\n",
      "R-squared: 0.3773279680203394\n",
      "Ridge Regression:\n",
      "Mean Squared Error: 12440.863966672623\n",
      "R-squared: 0.37599168951747\n",
      "Random Forest Regression:\n",
      "Mean Squared Error: 8105.981344444465\n",
      "R-squared: 0.5934205424076717\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Data Preparation\n",
    "data_copy = data.dropna(subset=['price_adjusted']).copy()  # Drop rows with missing target variable\n",
    "X = data_copy.drop(columns=['price_adjusted'])  # Independent variables\n",
    "y = data_copy['price_adjusted']  # Dependent variable\n",
    "\n",
    "# Step 2: Define the preprocessing steps\n",
    "# Handle missing values\n",
    "num_cols = X.select_dtypes(include='number').columns\n",
    "cat_cols = ['room_type']\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', SimpleImputer(strategy='mean'), num_cols),\n",
    "        ('cat', OneHotEncoder(), cat_cols)\n",
    "    ])\n",
    "\n",
    "# Step 3: Define the models with preprocessing in a Pipeline\n",
    "linear_model = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', LinearRegression())\n",
    "])\n",
    "\n",
    "ridge_model = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', Ridge(alpha=1.0))\n",
    "])\n",
    "\n",
    "rf_model = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', RandomForestRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "# Step 4: Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 5: Model Building and Evaluation\n",
    "models = {'Linear Regression': linear_model, 'Ridge Regression': ridge_model, 'Random Forest Regression': rf_model}\n",
    "best_model = None\n",
    "best_mse = float('inf')\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"{name}:\")\n",
    "    print(f\"Mean Squared Error: {mse}\")\n",
    "    print(f\"R-squared: {r2}\")\n",
    "    \n",
    "    if mse < best_mse:\n",
    "        best_model = model\n",
    "        best_mse = mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "24ab7652-c7f7-461f-a382-9dacf96d3b2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation R2 Scores: [0.53427625 0.53558056 0.69076289 0.70898619 0.66815026]\n",
      "Mean R2: 0.6275512276591882\n"
     ]
    }
   ],
   "source": [
    "# More cross validation with the best model Random Forest\n",
    "# Step 3: Define the best model with preprocessing in a Pipeline\n",
    "model_for_cv = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', RandomForestRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "# Step 5: Perform cross-validation with the best model\n",
    "cv_scores = cross_val_score(model_for_cv, X, y, cv=5, scoring='r2')\n",
    "cv_r2_scores = cv_scores\n",
    "\n",
    "print(\"Cross-Validation R2 Scores:\", cv_r2_scores)\n",
    "print(\"Mean R2:\", cv_r2_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2b61896e-d8bc-45c7-b504-cd5c0c6ae2d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'regressor__max_depth': None, 'regressor__n_estimators': 200}\n",
      "\n",
      "Best Model Performance:\n",
      "Mean Squared Error: 8109.2777470813635\n",
      "R-squared: 0.5932552015884462\n"
     ]
    }
   ],
   "source": [
    "# Very simple hyperparamter tuning, my computer does not have that much resources\n",
    "# Step 3: Define the model pipeline\n",
    "model = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', RandomForestRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "# Step 5: Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'regressor__n_estimators': [100, 200],  # Number of trees in the forest\n",
    "    'regressor__max_depth': [None, 10]  # Maximum depth of the trees\n",
    "}\n",
    "\n",
    "# Step 6: Perform GridSearchCV for hyperparameter tuning\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Step 7: Best parameters and best estimator\n",
    "best_params = grid_search.best_params_\n",
    "best_estimator = grid_search.best_estimator_\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "# Step 8: Evaluate the best model on the test set\n",
    "y_pred = best_estimator.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"\\nBest Model Performance:\")\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"R-squared: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f6b0c33e-dc61-4b9b-b0a9-ef5eeb30bdc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/price_model.pkl']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the best best_estimator\n",
    "joblib.dump(best_estimator, '../models/price_model.pkl')  # It seems this model is too big, I will change back to the default RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6ec325c9-e07d-4314-ac35-a1a40110598f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/price_model.pkl']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the best model\n",
    "joblib.dump(best_model, '../models/price_model.pkl')  # It seems this model is too big, I will change back to the default RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "43b98089-3f9c-4c5d-a661-2f87a205cbd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>accommodates</th>\n",
       "      <th>room_type</th>\n",
       "      <th>beds</th>\n",
       "      <th>bathroom_adjusted</th>\n",
       "      <th>price_adjusted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>19741.000000</td>\n",
       "      <td>19741.000000</td>\n",
       "      <td>19741.000000</td>\n",
       "      <td>19741</td>\n",
       "      <td>19620.000000</td>\n",
       "      <td>19698.000000</td>\n",
       "      <td>18901.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-123.112161</td>\n",
       "      <td>49.262765</td>\n",
       "      <td>3.545970</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.933792</td>\n",
       "      <td>1.351025</td>\n",
       "      <td>201.743664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.037972</td>\n",
       "      <td>0.020825</td>\n",
       "      <td>2.057082</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.180723</td>\n",
       "      <td>0.689773</td>\n",
       "      <td>141.954122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-123.221859</td>\n",
       "      <td>49.202960</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-123.130981</td>\n",
       "      <td>49.250200</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>110.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-123.115493</td>\n",
       "      <td>49.269060</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>160.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-123.090034</td>\n",
       "      <td>49.279000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>250.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>-123.023460</td>\n",
       "      <td>49.294360</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>999.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           longitude      latitude  accommodates        room_type  \\\n",
       "count   19741.000000  19741.000000  19741.000000            19741   \n",
       "unique           NaN           NaN           NaN                4   \n",
       "top              NaN           NaN           NaN  Entire home/apt   \n",
       "freq             NaN           NaN           NaN            16025   \n",
       "mean     -123.112161     49.262765      3.545970              NaN   \n",
       "std         0.037972      0.020825      2.057082              NaN   \n",
       "min      -123.221859     49.202960      1.000000              NaN   \n",
       "25%      -123.130981     49.250200      2.000000              NaN   \n",
       "50%      -123.115493     49.269060      3.000000              NaN   \n",
       "75%      -123.090034     49.279000      4.000000              NaN   \n",
       "max      -123.023460     49.294360     16.000000              NaN   \n",
       "\n",
       "                beds  bathroom_adjusted  price_adjusted  \n",
       "count   19620.000000       19698.000000    18901.000000  \n",
       "unique           NaN                NaN             NaN  \n",
       "top              NaN                NaN             NaN  \n",
       "freq             NaN                NaN             NaN  \n",
       "mean        1.933792           1.351025      201.743664  \n",
       "std         1.180723           0.689773      141.954122  \n",
       "min         1.000000           0.000000        1.000000  \n",
       "25%         1.000000           1.000000      110.000000  \n",
       "50%         2.000000           1.000000      160.000000  \n",
       "75%         2.000000           1.500000      250.000000  \n",
       "max        13.000000          10.000000      999.000000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aec5e411-d0ff-4b51-95ba-f8498eae696b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame(\n",
    "    {\"longitude\": -123.105090,\n",
    "     \"latitude\": 49.247730,\n",
    "     \"accommodates\": 4,\n",
    "     \"room_type\": 'Entire home/apt',\n",
    "     \"beds\": 3.0,\n",
    "     \"bathroom_adjusted\": 2.0},\n",
    "     index=[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "910878ac-a8da-4f09-b67f-7a33dd82b9f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>accommodates</th>\n",
       "      <th>room_type</th>\n",
       "      <th>beds</th>\n",
       "      <th>bathroom_adjusted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-123.10509</td>\n",
       "      <td>49.24773</td>\n",
       "      <td>4</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitude  latitude  accommodates        room_type  beds  bathroom_adjusted\n",
       "0 -123.10509  49.24773             4  Entire home/apt   3.0                2.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e179f590-34cf-402a-871c-327de81209b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "    new_data = pd.DataFrame({\n",
    "        'longitude': [-123.105090],\n",
    "        'latitude': [49.247730],\n",
    "        'accommodates': [4],\n",
    "        'room_type': ['Entire home/apt'],\n",
    "        'beds': [3.0],\n",
    "        'bathroom_adjusted': [2.0]\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f33b8391-3d1b-437a-a226-f4f60896f6b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>accommodates</th>\n",
       "      <th>room_type</th>\n",
       "      <th>beds</th>\n",
       "      <th>bathroom_adjusted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-123.10509</td>\n",
       "      <td>49.24773</td>\n",
       "      <td>4</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitude  latitude  accommodates        room_type  beds  bathroom_adjusted\n",
       "0 -123.10509  49.24773             4  Entire home/apt   3.0                2.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "404cec3e-7a56-498a-ab90-e73f91f92624",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.\nA suitable version of pyarrow or fastparquet is required for parquet support.\nTrying to import the above resulted in these errors:\n - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.\n - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprice_adjusted\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprice\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mextract(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m([0-9.]+)\u001b[39m\u001b[38;5;124m'\u001b[39m, expand \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mfloat\u001b[39m)\n\u001b[1;32m      9\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbathroom_adjusted\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbathrooms_text\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mextract(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m([0-9.]+)\u001b[39m\u001b[38;5;124m'\u001b[39m, expand \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mfloat\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../data/processed/listings.parquet\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/dash_env/lib/python3.8/site-packages/pandas/core/frame.py:2889\u001b[0m, in \u001b[0;36mDataFrame.to_parquet\u001b[0;34m(self, path, engine, compression, index, partition_cols, storage_options, **kwargs)\u001b[0m\n\u001b[1;32m   2802\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2803\u001b[0m \u001b[38;5;124;03mWrite a DataFrame to the binary parquet format.\u001b[39;00m\n\u001b[1;32m   2804\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2885\u001b[0m \u001b[38;5;124;03m>>> content = f.read()\u001b[39;00m\n\u001b[1;32m   2886\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2887\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparquet\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m to_parquet\n\u001b[0;32m-> 2889\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mto_parquet\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2890\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2891\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2892\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2893\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2894\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2895\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpartition_cols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpartition_cols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2896\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2897\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2898\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/dash_env/lib/python3.8/site-packages/pandas/io/parquet.py:407\u001b[0m, in \u001b[0;36mto_parquet\u001b[0;34m(df, path, engine, compression, index, storage_options, partition_cols, **kwargs)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(partition_cols, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    406\u001b[0m     partition_cols \u001b[38;5;241m=\u001b[39m [partition_cols]\n\u001b[0;32m--> 407\u001b[0m impl \u001b[38;5;241m=\u001b[39m \u001b[43mget_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    409\u001b[0m path_or_buf: FilePath \u001b[38;5;241m|\u001b[39m WriteBuffer[\u001b[38;5;28mbytes\u001b[39m] \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mBytesIO() \u001b[38;5;28;01mif\u001b[39;00m path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m path\n\u001b[1;32m    411\u001b[0m impl\u001b[38;5;241m.\u001b[39mwrite(\n\u001b[1;32m    412\u001b[0m     df,\n\u001b[1;32m    413\u001b[0m     path_or_buf,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    419\u001b[0m )\n",
      "File \u001b[0;32m/opt/miniconda3/envs/dash_env/lib/python3.8/site-packages/pandas/io/parquet.py:60\u001b[0m, in \u001b[0;36mget_engine\u001b[0;34m(engine)\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m     58\u001b[0m             error_msgs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m - \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(err)\n\u001b[0;32m---> 60\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m     61\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to find a usable engine; \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     62\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtried using: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpyarrow\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfastparquet\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     63\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA suitable version of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     64\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyarrow or fastparquet is required for parquet \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     65\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msupport.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     66\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrying to import the above resulted in these errors:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     67\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00merror_msgs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     68\u001b[0m     )\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m engine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyarrow\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m PyArrowImpl()\n",
      "\u001b[0;31mImportError\u001b[0m: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.\nA suitable version of pyarrow or fastparquet is required for parquet support.\nTrying to import the above resulted in these errors:\n - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.\n - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet."
     ]
    }
   ],
   "source": [
    "### binary storage\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"../data/raw/listings.csv\")\n",
    "df = df[df[\"host_location\"] == \"Vancouver, Canada\"]\n",
    "df.dropna(subset=['host_location', 'price', 'bathrooms_text'], inplace=True)\n",
    "df = df[[\"neighbourhood_cleansed\", \"accommodates\", \"price\", \"room_type\", \"beds\", \"bathrooms_text\", \"quarter\", \"latitude\", \"longitude\"]]\n",
    "\n",
    "df[\"price_adjusted\"] = df[\"price\"].str.extract(r'([0-9.]+)', expand = False).astype(float)\n",
    "df[\"bathroom_adjusted\"] = df[\"bathrooms_text\"].str.extract(r'([0-9.]+)', expand = False).astype(float)\n",
    "\n",
    "df.to_parquet('../data/processed/listings.parquet',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
